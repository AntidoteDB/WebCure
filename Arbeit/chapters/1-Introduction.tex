\chapter{Introduction}
\label{Introduction}

In this introductory chapter, we are going to discuss the motivation, research questions and the scope of this thesis.

\section{Motivation}
\label{Introduction-Motivation}

In modern days, with the speed the technology grows, the users always have their hopes high concerning having a more comfortable experience of working with web applications on their daily tasks. However, sometimes, even well-designed applications, which are expected to deliver better user experience, fail to do so and keep their users happy, due to the periods of disconnectivity that might occur. At such periods, for the matter of availability of the application, it should have its data on the client machine. That would allow users to maintain and perform different operations on their data while being offline or under poor network conditions. On the other hand, the updates performed offline at client side should be sent to the server, once the internet connection is back again. This is not an easy task, as, typically, one server could serve for multiple users. These users might deliver updates to the server at different times, so, the whole system should provide well-defined consistency\footnote{This and other concepts used in the introductory chapter will be defined in \chapref*{Background}.} guarantees to make the offline support possible, which many ad-hoc solutions could not do to this day.

In this thesis, we designed and implemented a framework for web applications, which we named \textbf{WebCure}. The problem we introduced above requires having the data to be partially replicated at the client side. With WebCure, we offer an approach of having a data store on a client. However, its purpose is not only to have the application available, when there is no internet connection. The client data store will be able to maintain the data coming from both sources: firstly, the data received from the server; and, secondly, the updates performed by the client, but which have not been delivered back to the server, yet. 

Additionally, for the web application to work offline and online, we are using a service worker. It serves as a programmable network proxy\cite{32}, allowing to manage how the network requests from the client are handled. When a client is offline, a service worker will redirect the requests coming from the client to its local storage. In the other situation, when a client has a connection, all the outgoing requests will proceed their way to a server side. This feature alone is a major positive regarding user experience, as it increases the availability of the application. 

On the other side, the server maintains cloud storage, based on AntidoteDB. We chose this database as our cloud storage server for the reason that it uses Conflict-Free replicated data types (CRDTs), which provide well-defined semantics for concurrent updates. We consider the next updates to be concurrent: the operations that are executed while a client is offline and the operations that are happening in the period between the last retrieval from the cloud storage server and the next connection and synchronisation to it. 

To sum it up, we developed the algorithms for WebCure and implemented a stable prototype of the framework. Apart from that, to evaluate WebCure's feasibility and performance, we ported a calendar application that allows for offline operations and demonstrates the advantages of our approach.

\section{Research questions}
\label{Introduction-Research}

Going through this thesis, our reader will find answers to the following research questions:

\begin{itemize}
    \item \textit{RQ1.} What could be a scalable solution for the transmission of CRDTs between a client and AntidoteDB-based server?
    \item \textit{RQ2.} What are the methods and technics available to implement web applications that would be able to work offline and
    in the conditions of poor network connections?
    \item \textit{RQ3.} How efficient is it to use a web-client with cache rather than without it?
  \end{itemize}

The research questions mentioned above are essential. Sometimes, there are some creative solutions to different problems that work, but just for one particular case. Therefore, it is always important to look for a solution, which can be scaled to different levels. On this matter, we are going to discuss the problem of transmission of CRDTs between a client and the server it interacts with. As CRDTs offer two ways of replicating data, a state-based approach and an operation-based approach, we are going to argue for the second one. The reason is that it has the benefits which are especially valuable for the system we are going to design, which will be explained later. Throughout this thesis, we are going to present the technique for implementing a web application, which is functional offline. However, even though our way to implement the offline work has advantages, there are also some other methods, which we are going to discuss in \chapref*{RelatedWork}. Regarding the last research question, as was already mentioned, in \chapref*{Evaluation} we will present the calendar application, which was extended with a feature of a client-side storage. There, we are going to share our thoughts on working with an app that has improved its functionality.

\section{Structure of Thesis}

In this section, we are going to give a summary of the structure of this thesis. 

We started with the introduction in \chapref*{Introduction}, where we described the motivation of the thesis in \secref*{Introduction-Motivation} and then the research questions, which we specified in \secref*{Introduction-Research}. 

Next, in \chapref*{Background}, we are going to talk about the fundamentals required to comprehend the idea of the paper: in \secref*{Background-Main} we are discussing the main theoretical concepts related to the distributed databases, while in \secref*{2-antidotedb} we introduce the cloud storage we are going to use for the server -- AntidoteDB, and in \secref*{2-crdts} we cover CRDTs in general. Additionally, there we describe the datatypes we used in our work. 

Afterwards, in \secref*{4-Requirements} and \secref*{4-Assumptions} we will talk about the requirements and assumptions we make for the system that we are going to design. Later, in \secref*{4-protocol} we will show in details how we came up with the protocol of the system. 

Then, there is \chapref*{Technologies}, where we are going to discuss the technologies, which we used to implement the described protocol. Mainly, we will talk about the client side of the system there.

Having explained all the previous topics, in \chapref*{Implementation}, we will go in details through the implementation of the system, starting discussing the main components of the system in \secref*{sysmaincomponents}.

Furthermore, in \chapref*{Evaluation} we will cover the topic on how we evaluated the system, where we will also show WebCure running in a Calendar application. Finally, in \chapref*{RelatedWork} we discuss other methods and technics that inspired us for this work. Then, in \chapref*{Conclusion} we will summarise the work of this thesis and in \secref*{futurework} we will talk about any future improvements and possible solutions that can be done over the current design of the system. 
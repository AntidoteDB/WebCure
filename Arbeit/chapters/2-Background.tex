\chapter{Theoretical background}
\label{Background}

In this chapter, we are going to introduce the reader to the theoretical concepts, which represent a prerequisite to have the understanding of this thesis.

\section{Main concepts}

\textit{Distributed database} -- it is a technology that combines two approaches of data processing: database system and computer network technologies\cite{11}. When we talk about \textit{geo-distributed databases}, however, we mean collections of data that are placed into different geographical locations.

Whenever we would like to interact with such a database, we deal with transactions. A \textit{transaction} is a basic unit of computing, which consits of sequence of operations that are exuted atomically on a database. Transactions transform a consistent database state to another consistent database state, even when they are executed concurrently. As long as each transaction is correct, a database that has a full transaction support guarantees that concurrent execution of user transactions will not violate database consistency \cite{11}. \textit{Consistency} requires transactions to change the data only according to the specified rules.

Two other terms we will need are \textit{linearizability} and \textit{serializability}. Linearizability defines a guarantee about single operations on single objects \cite{13}. It guarantees that the same operations are applied in the same order to every copy of the data item\cite{12}. While serializability is a guarantee about transactions, that they are executed serially on every set of the data items\cite{12}.

Now, let us introduce different consistency models and the one we will try to follow in the designing of our application. 

As stated by \citet{10}, \textit{strong consistency} model could be described in the following way: whenever the update is performed, everyone knows about it immediately. It means that there is a total order of updates and if there are two different clients that perform the same update, those updates will get some order and everyone will see the same order. The advantage of strong consistency is that it is good for fault tolerance and disadvantages are bad performance and it is problematic to scale.

On the other hand, there are some weaker consistency models that allow better scaling and improve performance. However, it creates problems on the fault tolerance side. In this thesis, we will try to stick with partial \textit{causal consistency}. As it is stated in \citet{7}, causal consistency is the strongest available and convergent model. They continue their statement saying that under causal consistency, every process observes a monotonically non-decreasing set of updates that includes its own updates, in an order that respects the causality between operations.

\section{AntidoteDB}

For this thesis, one of the core parts in the architecture of the WebCache belongs to the database called AntidoteDB\cite{4}. It is a good choice for the development of correct applications, because it has the same performance and horizontal scalability as AP / NoSQL\cite{14}, while it also:

\begin{itemize}
\item {is geo-distributed, which means that the datacenters of AntidoteDB could be spread across anywhere in the world}
\item {groups operations into atomic transactions\cite{9}}
\item {delivers updates in a causal order and merges concurrent operations}
\end{itemize} 

The last is possible because of Conflict-Free Replicated Datatypes (CRDTs) \cite{2}, which is used in AntidoteDB. It supports counters, sets, maps, multi-value registers and other types of data that are designed to work correctly in the presence of concurrent updates and failures. The usage of CRDTs allows the programmer to avoid problems that are common for other databases. We will cover the topic of CRDTs later in this chapter.

Apart from that, to replicate the data Antidote uses \textit{Cure}\cite{15}. It is a highly scalable protocol, which provides causal consistency, which was described earlier. It lets guarantee that, for example, in social networking applications, a user cannot see the reply to the post before the post itself.   

\section{Conflict-Free Replicated Datatypes}

As it is stated in \citet{3}, a conflict-free replicated datatype (CRDT) is an abstract datatype, which is designed for a possibility to be replicated among replicas and possesses the following properties:


    \begin{itemize}
        \item {The data at any replica could be modified independently of other replicas}
        \item {Replicas deterministically converge at the same state in case they received the same updates}
    \end{itemize}

Replication is a fundamental concept of distributed systems, well studied by the distributed algorithms community\cite{2}. There are two models of replication that are considered: state-based and operation-based. Eventually, we are going to use the operation-based approach. However, we are going to introduce our reader to both of them below. 

\subsection*{Operation-based replication approach}

\begin{figure}[!htb]
    \begin{center}
    \def\svgwidth{\linewidth}
    \input{images/crdts-replication/op-based.pdf_tex}
      {\scriptsize%
     Source: The figure is taken from \cite{2}}
    \caption {Operation-based approach.}
    \label{fig:theory1}
\end{center}
\end{figure}



In this thesis, we are going to use the operation-based replication approach, which originally means that replicas converge by propagating operations to every other replica\cite{3}. Once an operation is received in a replica, it is applied locally. That means, replicas don't exchange states with each other and as sometimes the full state could be a lot of data, it improves the efficiency. 

\subsection*{State-based replication approach}

\begin{figure}[!htb]
    \begin{center}
    \def\svgwidth{\linewidth}
    \input{images/crdts-replication/state-based.pdf_tex}
      {\scriptsize%
     Source: The figure is taken from \cite{2}}
    \caption {State-based approach.}
    \label{fig:theory2}
\end{center}
\end{figure}

The idea of this approach is kind of opposite to the operation-based one. Here, every replica, when receives an update, it first applies it locally. Afterwards, it sends it to other replicas. That means, that every replica sends its current full state to other replicas. When that happens, the merge function is happening between a local state and a received stated. The important thing is that every update eventually is going to appear at every other replica in the system. 